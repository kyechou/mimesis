%-------------------------------------------------------------------------------
\section{Related Work}
%-------------------------------------------------------------------------------

In this section, we discuss and compare our method with three other papers,
Plankton~\cite{2020-PrabhuEtAl}, Plankton-neo~\cite{2018-PrabhuEtAl}, and
Alembic~\cite{2019-MoonEtAl}. These papers are about network verification, or
trying to solve some issues emerged from network verification. However, each of
those targets a different problem and goal.

\textbf{Plankton} is a configuration verifier that manages the large header
space by using equivalence partitioning and explores protocol executions with
explicit-state model checking. It is the first prototype of a network verifier
that achieves high scalability using model checking. However, it uses
hand-written models for network components, assumes the correctness of those
models and does not handle the case where we may not have accurate models.

\textbf{Plankton-neo} is a hybrid approach combining Plankton with emulation,
with an aim to solve the problem that we do not have accurate models for some
network components, such as software network functions. Instead of writing a new
model for each middlebox in a network, it uses emulation to guarantee the
correctness of the middlebox's behavior. However, since Plankton-neo uses
emulations for middleboxes, it cannot handle the non-determinism inside the
middleboxes themselves (i.e., it may have multiple possible outputs given the
same input and the same current state, which are not fully explored), which
means that it cannot provide guaranteed coverage.

\textbf{Alembic} is a newly proposed model inference method. It treats network
functions as blackboxes, constructs symbolic rules from configuration
documentations at the offline stage, extends the L* algorithm to infer symbolic
models in the form of finite state machines, which essentially injects packets
that would exercise their symbolic rules, and then collects the library of
symbolic models for the online stage, where they plug in concrete configurations
to generate a corresponding concrete model. The generated model has improved
coverage compared to emulations, and also has comparable accuracy, although
there are not actually any ground truth to evaluate that. However, the Alembic
approach requires a lot of human effort at the offline stage, and can only be
applied on certain type of network function implementations. We expect to have a
more universal and applicable solution with better coverage/accuracy with binary
analysis, which is not completely blackbox testing.


%-------------------------------------------------------------------------------
% vim: set ft=tex :
