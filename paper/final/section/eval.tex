%-------------------------------------------------------------------------------
\section{Evaluation}
%-------------------------------------------------------------------------------

In order to evaluate the approach in different scenarios, we focus on two common
load balancing schemes, source-based hashing and round-robin, get the mapping
$f$ of inputs and outputs, and then make the solver engine generate valid
concrete values that satisfy the constraints. For performance evaluations, we
tested our optimized implementation of the simple load balancer, where we
manually pruned the irrelevant code sections so as to prevent unnecessary state
exploration. We also tested the unoptimized version with and without argument
parsing, and also different versions of HAProxy releases.

% machine and environment
All of the evaluation experiments were conducted on a Dell OptiPlex 7040
desktop, with an 8-core Intel Core i7-6700 CPU and 48 GiB DRAM, running Linux
5.4.2. However, all of the programs and scripts are single-threaded. We use the
latest PyPI release version of angr, 8.19.10.30, at the time of writing for the
experiments, with Python 3.8.0.


\subsection{Source-based hashing load balancing}
%-------------------------------------------------------------------------------

The input of the source-based hashing algorithm that affects the output (i.e.,
the backend server IP address and port) would be the client source address
(i.e., the source IP address and port of requests), which is used for hashing to
determine the output. In addition, the process of source-based hashing is
deterministic per flow across time. Namely, for each flow (or connection), the
result is deterministic no matter when it is executed, which is different from
the behavior of round-robin. We tested our approach in the following different
scenarios.

\begin{enumerate}
    \item Given a concrete client source address, find the output backend server
        address.

\begin{lstlisting}[language=bash]
$ python sourcehash/solve.py \
    --input-addr 0x7f000001 \
    --input-port 11111
cli_addr: 0x7f000001
cli_port: 11111
Addr: <BV64 0x7f000001>
Port: <BV64 0x2328>
Evaluated cli_addr: 0x7f000001
Evaluated cli_port: 11111
Evaluated addr: 0x7f000001
Evaluated port: 9000
\end{lstlisting}

        We can see that since the hashing algorithm is deterministic once the
        input client IP address and port is fixed, the resulting backend server
        address and port would also be concrete values.

    \item Given a concrete backend server address, find the input source address
        that leads to the output.

\begin{lstlisting}[language=bash]
$ python sourcehash/solve.py \
    --output-addr 0x7f000001 \
    --output-port 9003
cli_addr: <BV32 cli_ip_20_32>
cli_port: <BV16 cli_port_19_16>
Addr: <BV64 (AST with symbolic variable cli_ip and cli_port)>
Port: <BV64 (AST with symbolic variable cli_ip and cli_port)>
Evaluated cli_addr: 0x7f000001
Evaluated cli_port: 1026
Evaluated addr: 0x7f000001
Evaluated port: 9003
\end{lstlisting}

        In this case, we did not specify the input source address and port and
        set them to be symbolic values. As a result, the output server address
        and port would be arithmetic expressions of those symbolic values,
        represented in \texttt{angr} as abstract syntax trees (ASTs).

    \item Without any constraints on the input or output, get the relationship
        between them, and find a pair of concrete values that satisfy the
        relationship.

\begin{lstlisting}[language=bash]
$ python sourcehash/solve.py
cli_addr: <BV32 cli_ip_20_32>
cli_port: <BV16 cli_port_19_16>
Addr: <BV64 (AST with symbolic variable cli_ip and cli_port)>
Port: <BV64 (AST with symbolic variable cli_ip and cli_port)>
Evaluated cli_addr: 0x7f000001
Evaluated cli_port: 3074
Evaluated addr: 0x7f000001
Evaluated port: 9003
\end{lstlisting}

        When there are no explicit constraints on both the input and the output,
        the solver by default will find a random set of values that satisfy the
        expressions according to its internal heuristics. The next step is to
        store these abstract syntax trees and use some SAT/SMT solver like Z3 to
        find all possible solutions.
\end{enumerate}


\subsection{Round-robin load balancing}
%-------------------------------------------------------------------------------

The behavior of round-robin is non-deterministic per flow across time, since the
algorithm essentially does not care about the source address or port number, but
instead maintains an internal counter that loops through the possible choices of
the output backend servers. The input, in this case, would be irrelevant to the
output, i.e., the selected backend server address and port, and the internal
counter would be the key that determines the output. In consequence, we tested
the following scenarios.

\begin{enumerate}
    \item Given a concrete internal counter, find the output backend server
        address.

\begin{lstlisting}[language=bash]
$ python roundrobin/solve.py --counter 2
counter: <BV32 0x2>
Addr: <BV64 0x7f000001>
Port: <BV64 0x232a>
Evaluated counter: 2
Evaluated addr: 0x7f000001
Evaluated port: 9002
\end{lstlisting}

    \item Without constraining the internal counter variable, get the
        arithmetic expression of the output backend server address and port,
        which describes the relationship between the counter and the output.

\begin{lstlisting}[language=bash]
$ python roundrobin/solve.py
counter: <BV32 counter_19_32>
Addr: <BV64 (AST with symbolic variable counter_19_32)>
Port: <BV64 (AST with symbolic variable counter_19_32)>
Evaluated counter: 3
Evaluated addr: 0x7f000001
Evaluated port: 9003
\end{lstlisting}

        When there are no explicit constraints on both the internal counter,
        the solver by default will find a random set of values that satisfy the
        expressions according to its internal heuristics. As mentioned before,
        the next step would be to store these abstract syntax trees and use a
        solver to find all possible solutions, which should not be too hard to
        do.
\end{enumerate}

\subsection{Performance}
%-------------------------------------------------------------------------------

To evaluate the performance of our approach, we measured the time and peak
memory usage of the optimized implementation of source-based hashing load
balancing and round-robin load balancing, the time and peak memory usage of
reaching the \texttt{accept} function call instruction in the unoptimized
implementation, with and without argument parsing, and of applying the same
approach on various versions of HAProxy.

\subsubsection{Simple load balancer}

\begin{table}
\centering
\begin{tabular}{l r r}
\toprule
\textbf{Experiment} & \textbf{Time} & \textbf{Memory}\\
\midrule
Source-based hashing        & 2.90 sec & 129.278 MB \\
Round-robin                 & 2.99 sec & 129.033 MB \\
Unoptimized w/o arg parsing & 25.06 sec & 207.260 MB \\
Unoptimized w/ arg parsing  & 333.40 sec & 12064.724 MB \\
\bottomrule
\end{tabular}
\caption{Performance of optimized and unoptimized implementations of simple load
    balancer}
\label{perf-lb}
\end{table}

As shown in Table \ref{perf-lb}, the measurements of source-based hashing and
round-robin load balancing are the averages of ten runs for each experiment
setting, while for the experiments of reaching \texttt{accept} with and without
argument parsing in unoptimized implementation, the numbers are the result of
one execution.

We can see that the proposed method works well and terminates within reasonable
resource consumption for the cases of source-based hashing load balancing and
round-robin load balancing, where the implementation is optimized by pruning
unneeded code sections, such as parsing arguments, loading configuration
files, and complex format string handling, etc. However, for the unoptimized
version of our implementation, even reaching the \texttt{accept} function call
takes more time than getting the final expression in the optimized
implementation. This is the common state exploration problem in binary analysis
or other similar modelling systems, which we would elaborate in the limitations
section. However, the time and memory usage increased by around 13 times and 58
times just for the code parsing arguments. One way to circumvent this issue is
to install some instrumentation hooks through angr (or other binary analysis
tools), where we can implement a simplified version of \texttt{getopt} or
\texttt{getopt\_long} functions that handle the command-line arguments to
substitute the actual implementations in the program, although this can work
theoretically, but in practice, it would take a considerable amount of manpower
to implement these simulations of all the library functions used in a real-world
software.

\subsubsection{HAProxy}

\begin{table}
\centering
\begin{tabular}{l r r r}
\toprule
\textbf{Version} & \textbf{Time} & \textbf{Memory} & \textbf{Result}\\
\midrule
    1.5.0 & 2 min 56.94 sec &  525.912 MB & Deadend \\
    1.6.0 & 3 min 07.21 sec &  611.336 MB & Deadend \\
    1.7.0 & 5 min 31.05 sec &  875.484 MB & Deadend \\
    1.8.0 & 3 min 20.50 sec &  719.372 MB & Error \\
    1.9.0 & 3 min 57.71 sec &  862.072 MB & Error \\
    2.0.0 & 4 min 00.17 sec &  892.556 MB & Error \\
    2.1.0 & 8 min 41.95 sec & 1317.384 MB & Error \\
\bottomrule
\end{tabular}
\caption{Performance and results of different versions of HAProxy}
\label{perf-haproxy}
\end{table}

HAProxy is a popular, production-grade software load-balancer, widely adopted in
large applications, including Airbnb, DISQUS, Fedora, GitHub, Instagram, and
Reddit \cite{haproxy-they-use-it}. In this evaluation, we try to apply our
approach on the past 7 stable releases of HAProxy, and attempt to make the
symbolic execution engine reach the state at the \texttt{accept} function call
as the first step. However, as shown in Table \ref{perf-haproxy}, the results
were either deadend, which means that the execution engine had explored all
reachable execution paths of the binary given the context but failed to reach
the instruction that calls \texttt{accept}, or error, which means the binary
caused the analysis tool (i.e., angr) to throw some unexpected exception,
usually due to the bugs in the analysis tool or the fact that the tool does not
support some functionalities used in the program.

In spite of the deadends and unexpected exceptions, which means the explorations
terminate early, the time and memory consumptions still seem to be within the
reasonable range if we do these whole analysis and model extraction offline.


\subsection{Limitations}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
% vim: set ft=tex :
